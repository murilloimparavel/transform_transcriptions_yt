Thank you for joining me on BMAD code. 
Today I'm going to be showing you the 
amazing update to the BMAD method for 
agile AIdriven development. This method 
is elevated from feedback from the 
community and many of the viewers that 
have been watching and supporting this 
channel. I've taken your advice and I 
have made this method even more 
powerful. And today I'm going to show 
you how to maximize its potential. In 
the past video, I did say that we were 
going to build an application that can 
scrape hacker news top 10 stories, send 
out a daily digest, but we're going to 
take it to the next level. We're also 
going to have it build an actual AI 
generated podcast of the top news and 
comments from hacker news. It's going to 
be very fun to build and I'm going to 
show you how to do it with the power of 
the breakthrough method for agile 
AIdriven development or again we call it 
the BMAD method. Last time I showed you 
how to do the first four phases of the 
BMAD method in the IDE, but we're going 
to take it to the next level and do it 
in Gemini with the full power of 2.5 Pro 
and it's 1 million token context window. 
But the current V2 folder is the new 
version of the methodology. And this 
repo is going to go through all the 
details of why it's here. There's two 
main reasons that I updated. One is I 
wanted the agents that go into your IDE 
to be in parody with the agents that you 
might want to put into Gemini or Chat 
GPT custom gems. I've optimized all of 
them to make them lean and powerful and 
more interactive. So now instead of just 
asking for a PRD, having it ask you a 
few questions and then spit out the 
whole thing, it's going to work more 
interactive. Same thing for the 
architect. the business analyst and the 
scrum master and the PO. The V2 method 
is optimized for LLMs to develop with. 
Before we were producing a very large 
PRD and a very large architecture 
document, but the problem was the 
developer agents, they knew where to 
look at the story, but the developer 
agent also had to load the full PRD and 
the full architecture document to find 
the information that it needed. That was 
very inefficient and it led to bloat in 
the agent. It worked, but it was not 
ideal. With V2, everything is 
streamlined. So, let me show you. Go to 
the current V2 folder. You're going to 
see that there's gems and GPTs. This is 
for our four agents that we take and we 
actually put into Gemini or ChatgPT like 
I mentioned. But you also have all of 
the agents here still. So, you can have 
your custom scrum master or developer. 
But I recommend use the method I'm going 
to show you today where you take these 
and you actually put them into the web 
and set them up. We will use the 
analyst, the product manager or the 
architect and we will get the full power 
of the web and we will not waste any 
credits in cursor or wind surf or our 
own LLM going back and forth. Multiple 
people reached out to me last time and 
said just from the ideas that I shared 
last time because I did mention you 
could do this also in the web. People 
have told me individuals that they have 
already saved hundreds of dollars. One 
person even told me they saved over 
$1,000 in credits since switching over 
to my method. So, let me just show you 
how to set up one of these, but you can 
read these instructions. It's very 
simple. So, let's just jump over to the 
web. So, you'll come in here. You'll 
give it a name. I always start with a 
number because in Gemini you'll see this 
circle right here. The only thing you'll 
see to identify him when you're in the 
navigation. So I'm just going to call it 
architect 2 so I can keep it straight 
from the other one. So we're going to 
come to our architect gem. We're just 
going to copy everything here and we're 
going to paste it in here. Come to the 
instructions and you're going to look 
for the one that you're setting up. For 
the architect, we need the architecture 
template and the architecture checklist. 
We're going to click the plus button. 
Then we're going to say upload files, 
templates, and we're going to find our 
two architect files right here. We're 
going to make sure that they go blue 
like that. If they go red, that means it 
was an invalid file. Uh, now we're going 
to save it. Now, anytime you come back 
to Gemini, your custom gem is ready to 
go. Very similar process in OpenAI's 
chat GPT. They have custom GPTs. 
Here's where I use the BA. And first of 
all, this BA is a brainstorming wizard. 
It has actually three modes of working. 
It can do brainstorming for you. It can 
do deep research or it can jump right 
into producing the product briefing or 
the project briefing. The project 
briefing is the final output of the BA. 
And in it, it is not going to only not 
going to only have a small project 
brief, but it is also going to have a 
customized prompt ready to give to the 
PM. So I said,"I trying to make a simple 
app to demonstrate this whole 
methodology." Well, here I can help you 
brainstorm brainstorm some things. What 
are you trying to look for look to do? 
Maybe a simple utility on and on and on 
here, right? It's giving me some ideas. 
And I said, "Okay, you know what? You 
mentioned a to-do app. That might be a 
simple thing to do, but it could be kind 
of boring. What if we actually combined 
that with some AI or some LLM 
intelligence? Maybe that would be 
interesting." So, it gave me some more 
ideas. I thought about it and I'm like, 
"You know what? I don't want to do that. 
I think it would be fun have it scrape 
the top 10 stories and the articles 
they're linked from or linked to from 
Hacker News along with the comments. We 
can send an email with a daily briefing 
summarized by by an LLM. Since this is a 
demo and I want to keep it simple and 
show you the full app build, I want to 
keep it pretty simple and just develop 
everything locally. So, I brainstormed 
back and forth. I mentioned all that. I 
said that I would like to do a local 
LLM. I remind it that I also want to get 
the contents of the article, but I want 
to keep it simple. So, in this first 
one, it's saying there's a lot of 
chance, a lot of different challenges. 
You know, there's different ways to do 
scraping because there's JavaScript that 
could block content. There's security 
features. I said I just want to keep it 
simple. Let's just do the simplest way 
to scrape for right now. I want to use 
NodeJS. I want to use TypeScript. We're 
not going to deploy this. We're just 
going to do it locally. But in the 
future, I want to deploy this. So, I 
want to be able to use a local LLM just 
with Olama. And you know, I just want to 
keep it simple, but I also told it what 
I want to do in the future. 
Brainstorming back and forth to me. And 
this is one of the coolest things. I did 
not even expect this, but it suggested 
since I want to get the comments, as we 
were talking back and forth, I said, you 
know, thing, I want to do something a 
little bit different. What if our LLM 
also took all of the comments and then 
summarized that into an interesting 
summary and later we can pass this all 
off to the AI to produce a podcast of 
all of this content that we summarized. 
And it found out that there was this 
Angola API that basically makes it 
simpler to get all in one shot all of 
the comments already threaded from 
Hacker News instead of the normal way 
you do it through their API. I would 
have never thought of this. had thought 
of it and suggested to me and this will 
actually make it simpler and easier to 
get to the target that we want to do. 
So, very cool. Then say, okay, what do 
you want to name your project? I like 
that. I didn't even think of naming it 
and it said, what should I name it? It 
gave me a suggestion. I didn't like it. 
I said, how about the BMAD Hacker Daily 
Digest? It says, okay, does this 
basically sound good? I'm like, that is 
perfect. Let's do it. So, then it went 
to the next section, and this is doing 
it section by section. So, now it's 
going to talk about vision and goals. I 
said, "Yep, that's pretty good. I like 
it. I like that this is granular, going 
step by step, so I don't have to take in 
a lot of stuff all at once." So, it 
proposed it. I said, "Yeah, that's good. 
I like the scope." On and on and on, 
right? I'm not going to waste your time 
reading all of this. And this is a lot 
of me going back and forth really 
pushing on this because I just wanted to 
see all the things that this uh 
brainstorming was capable of. So, this 
is the end of the document. The whole 
document is ready to be output and it 
gave it that PM prompt. Now, at this 
point, what I would do is I would copy 
this and I would save it to a Google 
Doc. Um, and it's very simple to do 
because it gives you a copy button here. 
You can copy that and then once you copy 
it, just save it to a Google Doc. Save 
it. And then when you go to your PM 
prompt, go to explore gems. If you can't 
find it, I'm going to go to the PM 
attach right here. PM is going to 
produce a PRD and it is going to do like 
I said section by section ask you 
questions. It makes it really easy to 
take in these things. Now here already 
we have our PRD draft because it got 
such a detailed product brief. It was 
able to come up with this really quick 
and figure out what is MVP and what it 
suggests is not MVP. And then it's going 
to ask us section by section if we 
approve of everything. So it gave us the 
highlevel epics, but now it's going to 
create each epic one at a time and let 
us review it. And it's going to give us 
highle stories with acceptance criteria. 
So this is what it thinks the first 
story should be. I reviewed it and I 
said, "Okay, that looks good." It then 
gave us epic 2, epic 3, and epic 4. You 
want to capture each of those files and 
save those. And you can do just what I 
said before and save them as a Google 
doc, or you could be saving all of these 
right to your project. So you could just 
be putting them all right 
in right in our project. So you can see 
here I have started creating the project 
and collecting some of these files into 
a docs folder. So you can see I have all 
the epic files that it created. And you 
can also look ahead and see I have the 
PRD and a lot of the content. You see 
that there's many files in here. The 
architect is not just including one 
architecture file anymore. It's creating 
coding standards for us, data models, 
environment variables, product 
structure, very important. Jumping ahead 
though, back to the PM, we're going to 
be an active participant with this LLM. 
We are going to tell it to run the 
checklist. It's going to say, are you 
ready to run the checklist before we 
hand this off to the architect? This is 
the final approval from the PM for it to 
make sure that everything that it 
produced makes sense. Since it was doing 
everything granularly, it's now going to 
take all of those and holistically look 
at those, make sure it's meeting the 
goals of the product brief, its own uh 
PRD, and that the sequencing basically 
makes sense up to this point. So, it'll 
run through it's a pretty long 
checklist. It's checking a lot of 
things. It's actually considering other 
things here, too. It didn't find any 
critical issues. And this is the basic 
thing that you want to look for is this 
final output. It's very succinct and to 
the point. And if it does find anything, 
it will tell you. Now here, it's nice 
that it says it didn't find any critical 
deficiencies. The epics are 
comprehensive and aligned with the 
brief. It is approving that this is now 
ready for the architect. So, we're now 
ready to hand it off. Doing all of this 
in your IDE going back and forth with 
the 
LLM. It would just waste a lot of 
credits or you would be using very low 
powered models with low context windows 
and it's going to miss things. or you 
don't do this and then you're not really 
planning and you're gonna have gaps and 
potentially run into issues later on. 
This time in V2 of the BMAD method, the 
architect I think is the most improved 
because it's producing these granular 
small artifacts that the dev can really 
consume, but also it is tuned to work 
with you in an iterative fashion that is 
going to make you better able to 
understand what's going on and work with 
it and also learn a lot because it's 
going to work incrementally just like 
our PM did. So check this out. We put 
all our documents in here, the draft, 
PRD, and all the epics. And it already 
had a prompt given to us from the PM to 
to basically get the architect going. 
It's going to confirm that's going to be 
in architecture creation mode because 
the PM also has multiple modes. And it's 
going to start by first confirming the 
approach. It is going to say we can do 
yolo mode if we want. If we do that yolo 
mode, which I do not recommend, it's 
just going to spit out the whole 
architecture and it's going to probably 
not be as good of an artifact as it can 
if we go through the actual process. So, 
it doesn't take that long. And because 
this is going to do it granularly, 
you're going to understand everything 
every step of the way. So, first it's 
going to just tell you some of the 
foundational stuff and then it's going 
to go on to the technology selection. 
Here's what we're going to use for 
article article scraping. It found a 
library that I hadn't even considered 
and it's considering both of those and 
it actually tells you why it recommends 
one between the two. So instead of 
Cheurio, it's going to use article 
extractor from extractus. Now you can 
tell it no, you want to use something 
else here. Uh here, look, this is going 
to use date functions instead of the 
date, but I just love that this is 
explaining it very very clearly. So 
here's the summary of the dependencies 
it found. And I can just say, "Yep, go 
ahead and do that." And then it's going 
to do the same thing for the next 
section on and on and on. But this is 
tuned to communicate with you very 
clearly, 
explaining every decision that it makes 
or every choice that it makes. And it is 
going to make choices. That is another 
big benefit of the V2 version of the 
BMED method is sometimes it would leave 
thing leave things vague. For example, 
in the past, it would have probably said 
use Axios or fetch. Now, that's two 
different libraries that do the same 
thing, and it was kind of open-ended. 
Where that becomes a disaster is later 
on if you don't catch that and actually 
correct it to one later on when your 
agents are developing. Let's say they 
start using Axios to communicate with 
other APIs and then it goes into a test, 
failure, death spiral. You've seen this 
happen before with your agents, I bet. 
They start going around and around. They 
try changing the code. They try fixing 
the code. Things start breaking. The 
next thing that happens is it gets this 
dumb idea that, oh, maybe it's the 
library I'm using. I see this other 
library mentioned, so I'm just going to 
throw this other library. And then all 
of a sudden, you have two libraries in 
your project. You don't even realize it. 
And then just everything is off the 
rails. And that's all because sometimes 
things will be ambiguous, but not 
anymore. With this method, it will make 
sure that everything has a decision and 
doesn't leave it open-ended. So, you 
will work all the way through this 
architecture. You ex you can also 
suggest things to it. It will suggest 
things back to you. But it's just going 
to be such a wonderful learning process. 
And not only suggesting, but you can 
also ask questions. If it says it shows 
something over something else and you 
don't understand the explanation, ask it 
or challenge it. have it search the web. 
This thing is iterative and this can go 
on and on as long as you want to. But by 
really understanding and figuring all of 
this stuff out right now, we are going 
to have more chances of 
success as our project proceeds and 
grows. One thing with the architect is 
it's producing a lot of files. So to get 
all of those files out, you know, it 
could be a pain. Plus, a lot of these 
documents have mermaid embedded. So, I 
want to explain something very important 
to you about Gemini and also chat GPT. 
When you're in the web, all of the 
output you're seeing, such as this right 
here, is actually already markdown. So, 
the key change that I also made in V2, 
is the agents are not wrapping all of 
the output in markdown anymore. They're 
giving you markdown. And then sometimes 
this output will have embedded markdown. 
So that's why you still sometimes see 
something like this. This is 
markdown a code snippet. This is 
markdown that is plain text. Before 
copying this all out would get screwed 
up. But now what you can do is you just 
come to the end of the response here. 
Each time it's done responding there's 
going to be these triple dots. You click 
this. You click 
copy. And I just want you to notice that 
now this whole thing is perfect marked 
marked down. Nothing is mangled. And all 
you got to do is get rid of the 
beginning and get rid of the end here. 
Wherever the end 
is and it is right 
here. And now we have our perfectly 
extracted markdown. And the architect 
also will run a checklist. The most 
powerful one here though and if nothing 
else do this one in the web. This is so 
powerful. This PO takes all of your 
documents. So all of the you know six or 
eight architecture documents, all of 
your epic files with the highle stories 
and your PRD and it is going to analyze 
all of them. And this is where the huge 
context window of Gemini really pays off 
because it is specialtuned. All this 
does is run a checklist. All the PO does 
is run a checklist. There's not a lot of 
questioning back and forth. It is just 
checking that everything is in place, 
that you have a good solid framework in 
place, that you have any stories calling 
out manual setup that you as a user 
might need to do to get your project off 
the ground, such as setting up GitHub, 
um maybe purchasing API keys, 
registering accounts, getting 
infrastructure, whatever, right? It's 
going to make sure all of that is in 
place. It's also going to understand 
more than the other ones even that this 
is all going to be developed by very 
dumb developer agents. LLMs even with 
the most powerful models are still not 
that smart, right? They will still make 
mistakes without the proper context. So 
this thing knows that we need to have 
stories in a perfect sequence and we 
need to have all the architecture and 
other documentation around it to really 
give our developer agents the best 
chance of being able to just plow 
through our project and get it done 
right. So it is going to check for 
inconsistencies between the architecture 
and the PRD artifacts that were done 
before and make sure that they're all 
aligned. And at the very end we'll just 
jump ahead. It's going to analyze 
everything and it is going to give you a 
final decision where it says it was 
approved. Now, in this case, it did give 
us a summary. Everything passed, but it 
just found some minor deficiencies. The 
deficiencies it found were actually 
pretty funny. I forgot to attach one 
file to the PO, so it just thought that 
something was missing and it called it 
out. And it's something that would be 
needed in Epic 4. So, it was pretty 
minor, but said it would need to be 
created before Epic 4. So I just 
corrected it and told it oh actually 
that already exists. Please like this 
video and subscribe to the channel if 
you haven't. We are going to jump into 
cursor but you can be using any IDE and 
I'm going to show you how to actually 
now use the scrum master. The SM agent 
is tuned to produce one story at a time 
in draft mode which you then switch to 
the developer agent. This is basically 
where we want to live in our IDE. We're 
done with the web at this point. We've 
saved tons of money. We've had tons of 
power really producing amazing 
artifacts. These artifacts would have 
not been possible with Taskmaster or 
some of the other ones. They'll give you 
a good flow for simple projects, but you 
have to have very good prompts to feed 
into them to get that proper flow. And 
that is the artifacts that we produced 
that led up to this point. So now that 
we're here, we have the epics with our 
highlevel stories in in them. That is 
our tasks. The scrum master is going to 
draft a story in the IDE. We are going 
to approve it. We are going to start a 
new chat with the developer. The 
developer has its own custom 
instructions. So it knows exactly where 
these different story files are, how to 
use them, what the scrum master put into 
the story because the scrum master knows 
to pull all those all the various pieces 
of the architecture and the PRD and the 
epic. It looks at all of those files and 
it puts just what the developer agent 
needs into the story. I want to pause 
here and say a lot of the questions I 
got were about what do you do when the 
developer agent goes off the rails? And 
we're going to demonstrate that in our 
full app build. But if I can tell you 
one thing right now, if you're not 
already aware of this, never finish a 
story and then start a new story in the 
same chat window. The context is going 
to grow and you just don't need to do 
that. So keep starting new chat windows 
with your developer or your scrum 
master. But the second one is make sure 
that you're having the agent write tests 
and you work out your test plan with the 
architect. It will suggest something, 
but you can also suggest to it. But make 
sure that you have good test coverage, 
especially unit test coverage, which is 
the test that's granular against each 
little small piece of functional code. 
Those tests will save your ass time and 
again. When a story is implemented, you 
make sure all the tests pass, but you 
also make sure all of the tests for all 
of the previous stories pass. Only when 
they do, then you commit your code and 
you push it to the remote. Now the story 
is done. Now, you keep going on. Now, 
let's say you're halfway through the 
next story and something happened. It 
got screwed up. Maybe it got confused or 
you had a bad instruction in there and 
it starts throwing stuff all over the 
place and you don't know how to back out 
of it or get it on track or maybe you 
you get it stable, but it made a really 
big mess and now you don't know what to 
do. 
So many times I've seen it's better to 
throw that all out and go back to the 
beginning and since you pushed all of 
your stuff to the remote at the end of 
the last story, you're only going back 
to the beginning of the story. It's not 
too far back because these stories are 
meant to be granular incremental 
deliveries. And so it is easy to restore 
and start over and take a different 
approach. And maybe that different 
approach is looking in the story that 
the scrum master wrote and see if it 
made a mistake in there or see if you 
can clarify something in there so the 
dev agent will not make the same 
mistake. Make sure that you're 
committing often and pushing to the 
remote and then you can always go back 
in time to any point you need to if 
things go way off the rails. If you have 
a starter project or you can scaffold it 
yourself maybe with Nex.js, you know, 
project in it or Nest.js JS or something 
off the shelf. Get a baseline in place 
because you will save a lot of time and 
credits instead of trying to get like uh 
cursor or wind surf to scaffold all of 
that for you. It'll make mistakes or 
it'll screw up linting or some 
configuration. It's better to just start 
with a project baseline and tell your PM 
and your architect early on what 
settings you're starting with. It'll 
just make things a lot easier. I already 
did story one because this is just some 
basic setup of saying yes, the boiler 
plate is in place. 
The SM knows and I can just say draft 
the next story. It knows first of all to 
look in this folder. If it doesn't see 
anything in this stories folder, it will 
then see what epics are listed in the 
PRD and it will find the first epic epic 
one and it will see the first story is 
what needs to happen. Now in this case 
it will find a story here and it does 
see that the status is done. So, we 
should see that it looked to the 
template. So, it knows how to create the 
next story. It saw here that story one 
is done. So, it's going to check the 
epic and see what the next story is. And 
it found here that the next story should 
be story 1.2 because story 1.1 was done 
there. But I love that this workflow 
just knows how to find what is next and 
put it together. I'm going to finish 
epic one just because it's mostly manual 
manual setup. And then in the next 
video, we are going to be doing the 
exciting stuff of pulling the hacker 
news, creating LLM 
summaries, sending it in an email, 
scraping websites, and then generating 
an AI generated podcast. It's going to 
be a very exciting. So, I will see you 
soon. My name is Brian. Again, please 
like this video, subscribe to the 
channel, check out the repo, give me 
your comments and feedback and 
suggestions, and we can all help improve 
this workflow together. And I will see 
you in the next video.